{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection in Particle Physics Using AI at the LHC\n",
    "\n",
    "*Jordan Pfeifer, Ekin Secilmis, Egor Serebriakov*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the data used in the project\n",
    "\n",
    "We have three \"black boxes'' meant to be representative of the actual data from LHC. Each \"black box\" contains 1M events each. The given events might have signals that we consider as anomaly signals. \n",
    "\n",
    "Additionally, we have a background sample of 1M events simulated using Pythia8 and Delphes. This data was simulated in order to aid in the anomaly detection from the \"black boxes\". However, some assumption during the simulation might not exactly reflect the \"black boxes\" data.\n",
    "\n",
    "All datasets are stored as pandas DataFrames saved to compressed h5 format. Each event consists of 700 particles (we might have some events with some degree of zero padding) and each particle has three coordinates (pT, eta, phi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess, vae\n",
    "from preprocess import csv_preprocces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_box_dir = './anomaly detection/first_box_split'\n",
    "second_box_dir = './anomaly detection/second_box_split'\n",
    "third_box_dir = './anomaly detection/third_box_split'\n",
    "background_dir = './anomaly detection/background_split'\n",
    "\n",
    "filepath_first_box = f'{first_box_dir}/first_box_*.csv'\n",
    "filepath_second_box = f'{second_box_dir}/second_box_*.csv'\n",
    "filepath_third_box = f'{third_box_dir}/third_box_*.csv'\n",
    "filepath_background = f'{background_dir}/background_*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Data split ----------------------------\n",
      "test = 20.0%, validation = 10.0% of the train dataset.\n",
      "------------------------------------------------------------------\n",
      "Standardization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 23:05:51.878253: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------- Preprocessing is done ---------------------------\n",
      "The data is loaded as TensorFlow datasets, shuffled, split, standardized, and batched (batch = 32).\n",
      "Train dataset: 719986 elements in total.\n",
      "Test dataset 199996 elements.\n",
      "Validation dataset 79998 elements.\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 23:07:42.804974: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_valid = csv_preprocces(filepath_first_box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
